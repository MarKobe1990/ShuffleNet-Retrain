{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "753ae5b1-2f57-4f1c-ba12-0c2a6f62a23a",
   "metadata": {},
   "source": [
    "# 计算测试集图像语义特征\n",
    "\n",
    "抽取Pytorch训练得到的图像分类模型中间层的输出特征，作为输入图像的语义特征。\n",
    "\n",
    "计算测试集所有图像的语义特征，使用t-SNE和UMAP两种降维方法降维至二维和三维，可视化。\n",
    "\n",
    "分析不同类别的语义距离、异常数据、细粒度分类、高维数据结构。\n",
    "\n",
    "同济子豪兄：https://space.bilibili.com/1900783\n",
    "\n",
    "[代码运行云GPU环境](https://featurize.cn/?s=d7ce99f842414bfcaea5662a97581bd1)：GPU RTX 3060、CUDA v11.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a2a232f-0178-4661-98d8-f27f6fa130bf",
   "metadata": {},
   "source": [
    "## 导入工具包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57328106-567d-4be0-a0bc-1a20e88ceb01",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device cuda:0\n",
      "['covering', 'device', 'domestic_animal', 'mater', 'person', 'plant', 'structure', 'vertebrate']\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "# 忽略烦人的红色提示\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# 有 GPU 就用 GPU，没有就用 CPU\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print('device', device)\n",
    "dataset_name = 'test_easy_classes'\n",
    "model_path = 'models/2023-09-24-15:52_max_epoch_50/'\n",
    "\n",
    "# 类别名称 和 ID索引号 的映射字典\n",
    "class_names_dic = {0: 'covering', 1: 'device', 2: 'domestic_animal', 3: 'mater', 4: 'person', 5: 'plant',\n",
    "                       6: 'structure', 7: 'vertebrate'}\n",
    "# 获得类别名称\n",
    "classes = list(class_names_dic.values())\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7500ea23-53d8-4421-92f6-647d41e34d80",
   "metadata": {},
   "source": [
    "## 图像预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b562b97f-9a4a-4729-b238-4acb2e77e9dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "# # 训练集图像预处理：缩放裁剪、图像增强、转 Tensor、归一化\n",
    "# train_transform = transforms.Compose([transforms.RandomResizedCrop(224),\n",
    "#                                       transforms.RandomHorizontalFlip(),\n",
    "#                                       transforms.ToTensor(),\n",
    "#                                       transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "#                                      ])\n",
    "\n",
    "# 测试集图像预处理-RCTN：缩放、裁剪、转 Tensor、归一化\n",
    "test_transform = transforms.Compose([transforms.Resize(256),\n",
    "                                     transforms.CenterCrop(224),\n",
    "                                     transforms.ToTensor(),\n",
    "                                     transforms.Normalize(\n",
    "                                         mean=[0.485, 0.456, 0.406], \n",
    "                                         std=[0.229, 0.224, 0.225])\n",
    "                                    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a3347a-1c09-4b48-b19a-fbcc3791c08b",
   "metadata": {},
   "source": [
    "## 导入训练好的模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "618333ec-6e91-4342-acf3-86aaa1654068",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model size is  Medium\n"
     ]
    }
   ],
   "source": [
    "from network import ShuffleNetV2_Plus\n",
    "# 数据集文件夹路径\n",
    "dataset_name = 'test_easy_classes'\n",
    "model_path = 'models/2023-09-24-15:52_max_epoch_50/'\n",
    "model_name = 'retrain_COME15K_checkpoint-best-avg-0.735-Medium.pth.tar'\n",
    "dataset_dir = '../data_class_txt/'+ dataset_name + '.txt'\n",
    "# init model\n",
    "architecture = [0, 0, 3, 1, 1, 1, 0, 0, 2, 0, 2, 1, 1, 0, 2, 0, 2, 1, 3, 2]\n",
    "model = ShuffleNetV2_Plus(architecture=architecture, n_class=class_names_dic.__len__(), model_size=\"Medium\")\n",
    "weight_path = model_path + model_name\n",
    "trained_weight = torch.load(weight_path)\n",
    "model.load_state_dict(trained_weight['state_dict'], strict=True)\n",
    "model = model.eval().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bcb6264-8a76-433c-b7c9-bf18e5d93c15",
   "metadata": {},
   "source": [
    "## 导入训练好的模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd2c10b5-036e-4b0c-b967-947937b7340c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_and_weight_path = model_path + model_name\n",
    "model = torch.load(model_and_weight_path)\n",
    "model = model.eval().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e41c4cb2-e516-4150-9e9c-9580a26c72a3",
   "metadata": {},
   "source": [
    "## 抽取模型中间层输出结果作为语义特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a9fdf127-c713-4bb4-bcc8-4f808e011229",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torchvision.models.feature_extraction import create_feature_extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0a4dda05-7510-40a5-bc6f-6df80fdc4c64",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "TraceError",
     "evalue": "symbolically traced variables cannot be used as inputs to control flow",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTraceError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model_trunc \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_feature_extractor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_nodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mavgpool\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msemantic_feature\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torchvision/models/feature_extraction.py:441\u001b[0m, in \u001b[0;36mcreate_feature_extractor\u001b[0;34m(model, return_nodes, train_return_nodes, eval_return_nodes, tracer_kwargs, suppress_diff_warning)\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[38;5;66;03m# Instantiate our NodePathTracer and use that to trace the model\u001b[39;00m\n\u001b[1;32m    440\u001b[0m tracer \u001b[38;5;241m=\u001b[39m NodePathTracer(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtracer_kwargs)\n\u001b[0;32m--> 441\u001b[0m graph \u001b[38;5;241m=\u001b[39m \u001b[43mtracer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    443\u001b[0m name \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[1;32m    444\u001b[0m     model, nn\u001b[38;5;241m.\u001b[39mModule) \u001b[38;5;28;01melse\u001b[39;00m model\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\n\u001b[1;32m    445\u001b[0m graph_module \u001b[38;5;241m=\u001b[39m fx\u001b[38;5;241m.\u001b[39mGraphModule(tracer\u001b[38;5;241m.\u001b[39mroot, graph, name)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/fx/_symbolic_trace.py:615\u001b[0m, in \u001b[0;36mTracer.trace\u001b[0;34m(self, root, concrete_args)\u001b[0m\n\u001b[1;32m    613\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_autowrap_search:\n\u001b[1;32m    614\u001b[0m             _autowrap_check(patcher, module\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_autowrap_function_ids)\n\u001b[0;32m--> 615\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_node(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m'\u001b[39m, (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_arg(\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m),), {},\n\u001b[1;32m    616\u001b[0m                          type_expr\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__annotations__\u001b[39m\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreturn\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    618\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msubmodule_paths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    620\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgraph\n",
      "File \u001b[0;32m~/Documents/SODProject/ShuffleNet-Retrain/ShuffleNetV2+/network.py:89\u001b[0m, in \u001b[0;36mShuffleNetV2_Plus.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m     88\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfirst_conv(x)\n\u001b[0;32m---> 89\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     90\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv_last(x)\n\u001b[1;32m     92\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mglobalpool(x)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/fx/_symbolic_trace.py:604\u001b[0m, in \u001b[0;36mTracer.trace.<locals>.module_call_wrapper\u001b[0;34m(mod, *args, **kwargs)\u001b[0m\n\u001b[1;32m    600\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _orig_module_call(mod, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    602\u001b[0m _autowrap_check(patcher, \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mgetattr\u001b[39m(mod, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mforward\u001b[39m\u001b[38;5;124m\"\u001b[39m, mod), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__globals__\u001b[39m\u001b[38;5;124m\"\u001b[39m, {}),\n\u001b[1;32m    603\u001b[0m                 \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_autowrap_function_ids)\n\u001b[0;32m--> 604\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforward\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torchvision/models/feature_extraction.py:79\u001b[0m, in \u001b[0;36mNodePathTracer.call_module\u001b[0;34m(self, m, forward, args, kwargs)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_module_qualname \u001b[38;5;241m=\u001b[39m module_qualname\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_leaf_module(m, module_qualname):\n\u001b[0;32m---> 79\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_proxy(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcall_module\u001b[39m\u001b[38;5;124m'\u001b[39m, module_qualname, args, kwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/fx/_symbolic_trace.py:600\u001b[0m, in \u001b[0;36mTracer.trace.<locals>.module_call_wrapper.<locals>.forward\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    599\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 600\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_orig_module_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1103\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/container.py:141\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 141\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/fx/_symbolic_trace.py:604\u001b[0m, in \u001b[0;36mTracer.trace.<locals>.module_call_wrapper\u001b[0;34m(mod, *args, **kwargs)\u001b[0m\n\u001b[1;32m    600\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _orig_module_call(mod, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    602\u001b[0m _autowrap_check(patcher, \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mgetattr\u001b[39m(mod, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mforward\u001b[39m\u001b[38;5;124m\"\u001b[39m, mod), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__globals__\u001b[39m\u001b[38;5;124m\"\u001b[39m, {}),\n\u001b[1;32m    603\u001b[0m                 \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_autowrap_function_ids)\n\u001b[0;32m--> 604\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforward\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torchvision/models/feature_extraction.py:79\u001b[0m, in \u001b[0;36mNodePathTracer.call_module\u001b[0;34m(self, m, forward, args, kwargs)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_module_qualname \u001b[38;5;241m=\u001b[39m module_qualname\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_leaf_module(m, module_qualname):\n\u001b[0;32m---> 79\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_proxy(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcall_module\u001b[39m\u001b[38;5;124m'\u001b[39m, module_qualname, args, kwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/fx/_symbolic_trace.py:600\u001b[0m, in \u001b[0;36mTracer.trace.<locals>.module_call_wrapper.<locals>.forward\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    599\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 600\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_orig_module_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1103\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Documents/SODProject/ShuffleNet-Retrain/ShuffleNetV2+/blocks.py:106\u001b[0m, in \u001b[0;36mShufflenet.forward\u001b[0;34m(self, old_x)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, old_x):\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 106\u001b[0m         x_proj, x \u001b[38;5;241m=\u001b[39m \u001b[43mchannel_shuffle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mold_x\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    107\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcat((x_proj, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbranch_main(x)), \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    108\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n",
      "File \u001b[0;32m~/Documents/SODProject/ShuffleNet-Retrain/ShuffleNetV2+/blocks.py:197\u001b[0m, in \u001b[0;36mchannel_shuffle\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mchannel_shuffle\u001b[39m(x):\n\u001b[1;32m    196\u001b[0m     batchsize, num_channels, height, width \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39msize()\n\u001b[0;32m--> 197\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m (num_channels \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m4\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    198\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mreshape(batchsize \u001b[38;5;241m*\u001b[39m num_channels \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m2\u001b[39m, height \u001b[38;5;241m*\u001b[39m width)\n\u001b[1;32m    199\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/fx/proxy.py:251\u001b[0m, in \u001b[0;36mProxy.__bool__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__bool__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[0;32m--> 251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtracer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_bool\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/fx/proxy.py:152\u001b[0m, in \u001b[0;36mTracerBase.to_bool\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;129m@compatibility\u001b[39m(is_backward_compatible\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    146\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mto_bool\u001b[39m(\u001b[38;5;28mself\u001b[39m, obj: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mProxy\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[1;32m    147\u001b[0m     \u001b[38;5;124;03m\"\"\"Called when a proxy object is being converted to a boolean, such as\u001b[39;00m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;124;03m    when used in control flow.  Normally we don't know what to do because\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;124;03m    we don't know the value of the proxy, but a custom tracer can attach more\u001b[39;00m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;124;03m    information to the graph node using create_node and can choose to return a value.\u001b[39;00m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 152\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m TraceError(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msymbolically traced variables cannot be used as inputs to control flow\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mTraceError\u001b[0m: symbolically traced variables cannot be used as inputs to control flow"
     ]
    }
   ],
   "source": [
    "model_trunc = create_feature_extractor(model, return_nodes={'avgpool': 'semantic_feature'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b7137df-1c4a-452e-be96-de7ec6a5d85e",
   "metadata": {},
   "source": [
    "## 计算单张图像的语义特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "157f9102-fc51-468e-a43e-1a9256dfe22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = 'fruit30_split/val/菠萝/105.jpg'\n",
    "img_pil = Image.open(img_path)\n",
    "input_img = test_transform(img_pil) # 预处理\n",
    "input_img = input_img.unsqueeze(0).to(device)\n",
    "# 执行前向预测，得到指定中间层的输出\n",
    "pred_logits = model_trunc(input_img) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "108eb111-dc92-408c-8bf8-6111ad6a28e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_logits['semantic_feature'].squeeze().detach().cpu().numpy().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f70ba1f3-02c3-4bc7-92c2-5b0ee5a76762",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred_logits['semantic_feature'].squeeze().detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d681eb-d2af-4e54-bfa2-78590dffafbe",
   "metadata": {},
   "source": [
    "## 载入测试集图像分类结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6bb76734-83d2-49c9-ae35-3240595d5861",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('测试集预测结果.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6de3a2b3-0035-4f01-afbc-69b87e1af806",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>图像路径</th>\n",
       "      <th>标注类别ID</th>\n",
       "      <th>标注类别名称</th>\n",
       "      <th>top-1-预测ID</th>\n",
       "      <th>top-1-预测名称</th>\n",
       "      <th>top-2-预测ID</th>\n",
       "      <th>top-2-预测名称</th>\n",
       "      <th>top-3-预测ID</th>\n",
       "      <th>top-3-预测名称</th>\n",
       "      <th>top-n预测正确</th>\n",
       "      <th>...</th>\n",
       "      <th>草莓-预测置信度</th>\n",
       "      <th>荔枝-预测置信度</th>\n",
       "      <th>菠萝-预测置信度</th>\n",
       "      <th>葡萄-白-预测置信度</th>\n",
       "      <th>葡萄-红-预测置信度</th>\n",
       "      <th>西瓜-预测置信度</th>\n",
       "      <th>西红柿-预测置信度</th>\n",
       "      <th>车厘子-预测置信度</th>\n",
       "      <th>香蕉-预测置信度</th>\n",
       "      <th>黄瓜-预测置信度</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fruit30_split/val/哈密瓜/106.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>哈密瓜</td>\n",
       "      <td>4.0</td>\n",
       "      <td>柚子</td>\n",
       "      <td>5.0</td>\n",
       "      <td>柠檬</td>\n",
       "      <td>7.0</td>\n",
       "      <td>梨</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.810175e-07</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>1.294236e-04</td>\n",
       "      <td>3.994173e-07</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>5.830796e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fruit30_split/val/哈密瓜/109.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>哈密瓜</td>\n",
       "      <td>6.0</td>\n",
       "      <td>桂圆</td>\n",
       "      <td>0.0</td>\n",
       "      <td>哈密瓜</td>\n",
       "      <td>8.0</td>\n",
       "      <td>椰子</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.460142e-08</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.001481</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>0.000175</td>\n",
       "      <td>7.725556e-07</td>\n",
       "      <td>3.171619e-06</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>2.559105e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fruit30_split/val/哈密瓜/114.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>哈密瓜</td>\n",
       "      <td>0.0</td>\n",
       "      <td>哈密瓜</td>\n",
       "      <td>26.0</td>\n",
       "      <td>西红柿</td>\n",
       "      <td>23.0</td>\n",
       "      <td>葡萄-白</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9.829248e-03</td>\n",
       "      <td>0.007687</td>\n",
       "      <td>0.001150</td>\n",
       "      <td>0.040230</td>\n",
       "      <td>0.035187</td>\n",
       "      <td>0.001550</td>\n",
       "      <td>2.761092e-01</td>\n",
       "      <td>1.695518e-04</td>\n",
       "      <td>0.006084</td>\n",
       "      <td>1.219466e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fruit30_split/val/哈密瓜/116.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>哈密瓜</td>\n",
       "      <td>0.0</td>\n",
       "      <td>哈密瓜</td>\n",
       "      <td>16.0</td>\n",
       "      <td>芒果</td>\n",
       "      <td>4.0</td>\n",
       "      <td>柚子</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.417844e-05</td>\n",
       "      <td>0.000247</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>0.001455</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000460</td>\n",
       "      <td>8.358340e-04</td>\n",
       "      <td>2.168997e-07</td>\n",
       "      <td>0.022086</td>\n",
       "      <td>4.123446e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fruit30_split/val/哈密瓜/118.png</td>\n",
       "      <td>0</td>\n",
       "      <td>哈密瓜</td>\n",
       "      <td>4.0</td>\n",
       "      <td>柚子</td>\n",
       "      <td>11.0</td>\n",
       "      <td>猕猴桃</td>\n",
       "      <td>23.0</td>\n",
       "      <td>葡萄-白</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.725807e-04</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>0.091698</td>\n",
       "      <td>0.000659</td>\n",
       "      <td>0.000463</td>\n",
       "      <td>3.796561e-03</td>\n",
       "      <td>3.087181e-08</td>\n",
       "      <td>0.000306</td>\n",
       "      <td>5.176165e-04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            图像路径  标注类别ID 标注类别名称  top-1-预测ID top-1-预测名称  \\\n",
       "0  fruit30_split/val/哈密瓜/106.jpg       0    哈密瓜         4.0         柚子   \n",
       "1  fruit30_split/val/哈密瓜/109.jpg       0    哈密瓜         6.0         桂圆   \n",
       "2  fruit30_split/val/哈密瓜/114.jpg       0    哈密瓜         0.0        哈密瓜   \n",
       "3  fruit30_split/val/哈密瓜/116.jpg       0    哈密瓜         0.0        哈密瓜   \n",
       "4  fruit30_split/val/哈密瓜/118.png       0    哈密瓜         4.0         柚子   \n",
       "\n",
       "   top-2-预测ID top-2-预测名称  top-3-预测ID top-3-预测名称  top-n预测正确  ...      草莓-预测置信度  \\\n",
       "0         5.0         柠檬         7.0          梨        0.0  ...  1.810175e-07   \n",
       "1         0.0        哈密瓜         8.0         椰子        1.0  ...  8.460142e-08   \n",
       "2        26.0        西红柿        23.0       葡萄-白        1.0  ...  9.829248e-03   \n",
       "3        16.0         芒果         4.0         柚子        1.0  ...  4.417844e-05   \n",
       "4        11.0        猕猴桃        23.0       葡萄-白        0.0  ...  7.725807e-04   \n",
       "\n",
       "   荔枝-预测置信度  菠萝-预测置信度  葡萄-白-预测置信度  葡萄-红-预测置信度  西瓜-预测置信度     西红柿-预测置信度  \\\n",
       "0  0.000001  0.000003    0.000010    0.000006  0.000111  1.294236e-04   \n",
       "1  0.000001  0.000001    0.001481    0.000045  0.000175  7.725556e-07   \n",
       "2  0.007687  0.001150    0.040230    0.035187  0.001550  2.761092e-01   \n",
       "3  0.000247  0.000071    0.001455    0.000003  0.000460  8.358340e-04   \n",
       "4  0.000075  0.000089    0.091698    0.000659  0.000463  3.796561e-03   \n",
       "\n",
       "      车厘子-预测置信度  香蕉-预测置信度      黄瓜-预测置信度  \n",
       "0  3.994173e-07  0.000004  5.830796e-07  \n",
       "1  3.171619e-06  0.000033  2.559105e-06  \n",
       "2  1.695518e-04  0.006084  1.219466e-03  \n",
       "3  2.168997e-07  0.022086  4.123446e-04  \n",
       "4  3.087181e-08  0.000306  5.176165e-04  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e7d010-df35-4fb9-8dcb-1af2d5399681",
   "metadata": {},
   "source": [
    "## 计算测试集每张图像的语义特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0d630667-6b6b-4fdd-8c4d-28286499330b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1079/1079 [00:15<00:00, 71.71it/s]\n"
     ]
    }
   ],
   "source": [
    "encoding_array = []\n",
    "img_path_list = []\n",
    "\n",
    "for img_path in tqdm(df['图像路径']):\n",
    "    img_path_list.append(img_path)\n",
    "    img_pil = Image.open(img_path).convert('RGB')\n",
    "    input_img = test_transform(img_pil).unsqueeze(0).to(device) # 预处理\n",
    "    feature = model_trunc(input_img)['semantic_feature'].squeeze().detach().cpu().numpy() # 执行前向预测，得到 avgpool 层输出的语义特征\n",
    "    encoding_array.append(feature)\n",
    "encoding_array = np.array(encoding_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fec12f5b-35d0-4367-8ac1-7d7321eecee9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1079, 512)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding_array.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c434aad3-9689-4e77-bef7-1daa4400e590",
   "metadata": {},
   "source": [
    "## 保存为本地的.npy文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "896a318d-430c-4b59-9c94-0b08ba0106dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存为本地的 npy 文件\n",
    "np.save('测试集语义特征.npy', encoding_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4417cdc4-0bad-428c-896f-1d35d31401a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:SemanticTest]",
   "language": "python",
   "name": "conda-env-SemanticTest-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
