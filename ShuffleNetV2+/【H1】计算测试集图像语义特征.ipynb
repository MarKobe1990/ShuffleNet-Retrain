{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "753ae5b1-2f57-4f1c-ba12-0c2a6f62a23a",
   "metadata": {},
   "source": [
    "# 计算测试集图像语义特征\n",
    "\n",
    "抽取Pytorch训练得到的图像分类模型中间层的输出特征，作为输入图像的语义特征。\n",
    "\n",
    "计算测试集所有图像的语义特征，使用t-SNE和UMAP两种降维方法降维至二维和三维，可视化。\n",
    "\n",
    "分析不同类别的语义距离、异常数据、细粒度分类、高维数据结构。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a2a232f-0178-4661-98d8-f27f6fa130bf",
   "metadata": {},
   "source": [
    "## 导入工具包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57328106-567d-4be0-a0bc-1a20e88ceb01",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device cuda:0\n",
      "['covering', 'device', 'domestic_animal', 'mater', 'person', 'plant', 'structure', 'vertebrate']\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "# 忽略烦人的红色提示\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# 有 GPU 就用 GPU，没有就用 CPU\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print('device', device)\n",
    "dataset_name = 'test_easy_classes'\n",
    "model_path = 'models/2023-09-24-15:52_max_epoch_50/'\n",
    "\n",
    "# 类别名称 和 ID索引号 的映射字典\n",
    "class_names_dic = {0: 'covering', 1: 'device', 2: 'domestic_animal', 3: 'mater', 4: 'person', 5: 'plant',\n",
    "                       6: 'structure', 7: 'vertebrate'}\n",
    "# 获得类别名称\n",
    "classes = list(class_names_dic.values())\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7500ea23-53d8-4421-92f6-647d41e34d80",
   "metadata": {},
   "source": [
    "## 图像预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b562b97f-9a4a-4729-b238-4acb2e77e9dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "# # 训练集图像预处理：缩放裁剪、图像增强、转 Tensor、归一化\n",
    "# train_transform = transforms.Compose([transforms.RandomResizedCrop(224),\n",
    "#                                       transforms.RandomHorizontalFlip(),\n",
    "#                                       transforms.ToTensor(),\n",
    "#                                       transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "#                                      ])\n",
    "\n",
    "# 测试集图像预处理-RCTN：缩放、裁剪、转 Tensor、归一化\n",
    "test_transform = transforms.Compose([transforms.Resize(256),\n",
    "                                     transforms.CenterCrop(224),\n",
    "                                     transforms.ToTensor(),\n",
    "                                     transforms.Normalize(\n",
    "                                         mean=[0.485, 0.456, 0.406], \n",
    "                                         std=[0.229, 0.224, 0.225])\n",
    "                                    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a3347a-1c09-4b48-b19a-fbcc3791c08b",
   "metadata": {},
   "source": [
    "## 导入训练好的模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "618333ec-6e91-4342-acf3-86aaa1654068",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model size is  Medium\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ShuffleNetV2_Plus(\n",
       "  (first_conv): Sequential(\n",
       "    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): HS()\n",
       "  )\n",
       "  (features): Sequential(\n",
       "    (0): Shufflenet(\n",
       "      (branch_main): Sequential(\n",
       "        (0): Conv2d(16, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(24, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=24, bias=False)\n",
       "        (4): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): Conv2d(24, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (6): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (7): ReLU(inplace=True)\n",
       "      )\n",
       "      (branch_proj): Sequential(\n",
       "        (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=16, bias=False)\n",
       "        (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Shufflenet(\n",
       "      (branch_main): Sequential(\n",
       "        (0): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24, bias=False)\n",
       "        (4): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (6): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (7): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (2): Shuffle_Xception(\n",
       "      (branch_main): Sequential(\n",
       "        (0): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24, bias=False)\n",
       "        (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24, bias=False)\n",
       "        (6): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (7): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (8): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (9): ReLU(inplace=True)\n",
       "        (10): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24, bias=False)\n",
       "        (11): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (12): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (13): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (14): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (3): Shufflenet(\n",
       "      (branch_main): Sequential(\n",
       "        (0): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(24, 24, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=24, bias=False)\n",
       "        (4): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (6): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (7): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (4): Shufflenet(\n",
       "      (branch_main): Sequential(\n",
       "        (0): Conv2d(48, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): HS()\n",
       "        (3): Conv2d(64, 64, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=64, bias=False)\n",
       "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): Conv2d(64, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (6): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (7): HS()\n",
       "      )\n",
       "      (branch_proj): Sequential(\n",
       "        (0): Conv2d(48, 48, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=48, bias=False)\n",
       "        (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): HS()\n",
       "      )\n",
       "    )\n",
       "    (5): Shufflenet(\n",
       "      (branch_main): Sequential(\n",
       "        (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): HS()\n",
       "        (3): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=64, bias=False)\n",
       "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (6): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (7): HS()\n",
       "      )\n",
       "    )\n",
       "    (6): Shufflenet(\n",
       "      (branch_main): Sequential(\n",
       "        (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): HS()\n",
       "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
       "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (6): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (7): HS()\n",
       "      )\n",
       "    )\n",
       "    (7): Shufflenet(\n",
       "      (branch_main): Sequential(\n",
       "        (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): HS()\n",
       "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
       "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (6): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (7): HS()\n",
       "      )\n",
       "    )\n",
       "    (8): Shufflenet(\n",
       "      (branch_main): Sequential(\n",
       "        (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): HS()\n",
       "        (3): Conv2d(128, 128, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), groups=128, bias=False)\n",
       "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (6): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (7): HS()\n",
       "        (8): SELayer(\n",
       "          (SE_opr): Sequential(\n",
       "            (0): AdaptiveAvgPool2d(output_size=1)\n",
       "            (1): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (3): ReLU(inplace=True)\n",
       "            (4): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (branch_proj): Sequential(\n",
       "        (0): Conv2d(128, 128, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), groups=128, bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): HS()\n",
       "      )\n",
       "    )\n",
       "    (9): Shufflenet(\n",
       "      (branch_main): Sequential(\n",
       "        (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): HS()\n",
       "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
       "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (6): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (7): HS()\n",
       "        (8): SELayer(\n",
       "          (SE_opr): Sequential(\n",
       "            (0): AdaptiveAvgPool2d(output_size=1)\n",
       "            (1): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (3): ReLU(inplace=True)\n",
       "            (4): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (10): Shufflenet(\n",
       "      (branch_main): Sequential(\n",
       "        (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): HS()\n",
       "        (3): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128, bias=False)\n",
       "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (6): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (7): HS()\n",
       "        (8): SELayer(\n",
       "          (SE_opr): Sequential(\n",
       "            (0): AdaptiveAvgPool2d(output_size=1)\n",
       "            (1): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (3): ReLU(inplace=True)\n",
       "            (4): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (11): Shufflenet(\n",
       "      (branch_main): Sequential(\n",
       "        (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): HS()\n",
       "        (3): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=128, bias=False)\n",
       "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (6): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (7): HS()\n",
       "        (8): SELayer(\n",
       "          (SE_opr): Sequential(\n",
       "            (0): AdaptiveAvgPool2d(output_size=1)\n",
       "            (1): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (3): ReLU(inplace=True)\n",
       "            (4): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (12): Shufflenet(\n",
       "      (branch_main): Sequential(\n",
       "        (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): HS()\n",
       "        (3): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=128, bias=False)\n",
       "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (6): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (7): HS()\n",
       "        (8): SELayer(\n",
       "          (SE_opr): Sequential(\n",
       "            (0): AdaptiveAvgPool2d(output_size=1)\n",
       "            (1): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (3): ReLU(inplace=True)\n",
       "            (4): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (13): Shufflenet(\n",
       "      (branch_main): Sequential(\n",
       "        (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): HS()\n",
       "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
       "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (6): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (7): HS()\n",
       "        (8): SELayer(\n",
       "          (SE_opr): Sequential(\n",
       "            (0): AdaptiveAvgPool2d(output_size=1)\n",
       "            (1): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (3): ReLU(inplace=True)\n",
       "            (4): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (14): Shufflenet(\n",
       "      (branch_main): Sequential(\n",
       "        (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): HS()\n",
       "        (3): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128, bias=False)\n",
       "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (6): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (7): HS()\n",
       "        (8): SELayer(\n",
       "          (SE_opr): Sequential(\n",
       "            (0): AdaptiveAvgPool2d(output_size=1)\n",
       "            (1): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (3): ReLU(inplace=True)\n",
       "            (4): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (15): Shufflenet(\n",
       "      (branch_main): Sequential(\n",
       "        (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): HS()\n",
       "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
       "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (6): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (7): HS()\n",
       "        (8): SELayer(\n",
       "          (SE_opr): Sequential(\n",
       "            (0): AdaptiveAvgPool2d(output_size=1)\n",
       "            (1): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (3): ReLU(inplace=True)\n",
       "            (4): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (16): Shufflenet(\n",
       "      (branch_main): Sequential(\n",
       "        (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): HS()\n",
       "        (3): Conv2d(256, 256, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), groups=256, bias=False)\n",
       "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (7): HS()\n",
       "        (8): SELayer(\n",
       "          (SE_opr): Sequential(\n",
       "            (0): AdaptiveAvgPool2d(output_size=1)\n",
       "            (1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (3): ReLU(inplace=True)\n",
       "            (4): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (branch_proj): Sequential(\n",
       "        (0): Conv2d(256, 256, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), groups=256, bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): HS()\n",
       "      )\n",
       "    )\n",
       "    (17): Shufflenet(\n",
       "      (branch_main): Sequential(\n",
       "        (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): HS()\n",
       "        (3): Conv2d(256, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=256, bias=False)\n",
       "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (7): HS()\n",
       "        (8): SELayer(\n",
       "          (SE_opr): Sequential(\n",
       "            (0): AdaptiveAvgPool2d(output_size=1)\n",
       "            (1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (3): ReLU(inplace=True)\n",
       "            (4): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (18): Shuffle_Xception(\n",
       "      (branch_main): Sequential(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): HS()\n",
       "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
       "        (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (7): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (8): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (9): HS()\n",
       "        (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
       "        (11): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (12): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (13): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (14): HS()\n",
       "        (15): SELayer(\n",
       "          (SE_opr): Sequential(\n",
       "            (0): AdaptiveAvgPool2d(output_size=1)\n",
       "            (1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (3): ReLU(inplace=True)\n",
       "            (4): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (19): Shufflenet(\n",
       "      (branch_main): Sequential(\n",
       "        (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): HS()\n",
       "        (3): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256, bias=False)\n",
       "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (7): HS()\n",
       "        (8): SELayer(\n",
       "          (SE_opr): Sequential(\n",
       "            (0): AdaptiveAvgPool2d(output_size=1)\n",
       "            (1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (3): ReLU(inplace=True)\n",
       "            (4): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (conv_last): Sequential(\n",
       "    (0): Conv2d(512, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): HS()\n",
       "  )\n",
       "  (globalpool): AvgPool2d(kernel_size=7, stride=7, padding=0)\n",
       "  (LastSE): SELayer(\n",
       "    (SE_opr): Sequential(\n",
       "      (0): AdaptiveAvgPool2d(output_size=1)\n",
       "      (1): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (2): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): ReLU(inplace=True)\n",
       "      (4): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    )\n",
       "  )\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "    (1): HS()\n",
       "  )\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=1280, out_features=8, bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from network import ShuffleNetV2_Plus\n",
    "# 数据集文件夹路径\n",
    "dataset_name = 'test_easy_classes'\n",
    "model_path = 'models/2023-09-24-15:52_max_epoch_50/'\n",
    "model_name = 'retrain_COME15K_checkpoint-best-avg-0.735-Medium.pth.tar'\n",
    "dataset_dir = '../data_class_txt/'+ dataset_name + '.txt'\n",
    "# init model\n",
    "architecture = [0, 0, 3, 1, 1, 1, 0, 0, 2, 0, 2, 1, 1, 0, 2, 0, 2, 1, 3, 2]\n",
    "model = ShuffleNetV2_Plus(architecture=architecture, n_class=class_names_dic.__len__(), model_size=\"Medium\")\n",
    "weight_path = model_path + model_name\n",
    "trained_weight = torch.load(weight_path)\n",
    "model.load_state_dict(trained_weight['state_dict'], strict=True)\n",
    "model = model.eval().to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bcb6264-8a76-433c-b7c9-bf18e5d93c15",
   "metadata": {},
   "source": [
    "globalpool## 导入训练好的模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd2c10b5-036e-4b0c-b967-947937b7340c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'eval'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m model_and_weight_path \u001b[38;5;241m=\u001b[39m model_path \u001b[38;5;241m+\u001b[39m model_name\n\u001b[1;32m      2\u001b[0m model \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(model_and_weight_path)\n\u001b[0;32m----> 3\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval\u001b[49m()\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      4\u001b[0m model\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'eval'"
     ]
    }
   ],
   "source": [
    "model_and_weight_path = model_path + model_name\n",
    "model = torch.load(model_and_weight_path)\n",
    "model = model.eval().to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e41c4cb2-e516-4150-9e9c-9580a26c72a3",
   "metadata": {},
   "source": [
    "## 抽取模型中间层输出结果作为语义特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a9fdf127-c713-4bb4-bcc8-4f808e011229",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torchvision.models.feature_extraction import create_feature_extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0a4dda05-7510-40a5-bc6f-6df80fdc4c64",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_trunc = create_feature_extractor(model, return_nodes={'globalpool': 'semantic_feature'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b7137df-1c4a-452e-be96-de7ec6a5d85e",
   "metadata": {},
   "source": [
    "## 计算单张图像的语义特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "157f9102-fc51-468e-a43e-1a9256dfe22a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "img_path = 'data/SOD-SemanticDataset/test/COME15K-Hard/COME_Hard_1.jpg'\n",
    "img_pil = Image.open(img_path)\n",
    "input_img = test_transform(img_pil) # 预处理\n",
    "input_img = input_img.unsqueeze(0).to(device)\n",
    "# 执行前向预测，得到指定中间层的输出\n",
    "pred_logits = model_trunc(input_img) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "108eb111-dc92-408c-8bf8-6111ad6a28e7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1280,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_logits['semantic_feature'].squeeze().detach().cpu().numpy().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f70ba1f3-02c3-4bc7-92c2-5b0ee5a76762",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.03510536,  0.35254237,  0.16077131, ..., -0.03608838,\n",
       "        0.3300721 ,  0.34675378], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_logits['semantic_feature'].squeeze().detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d681eb-d2af-4e54-bfa2-78590dffafbe",
   "metadata": {},
   "source": [
    "## 载入测试集图像分类结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6bb76734-83d2-49c9-ae35-3240595d5861",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(model_path + dataset_name + '-测试集预测结果.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6de3a2b3-0035-4f01-afbc-69b87e1af806",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>图像路径</th>\n",
       "      <th>标注类别ID</th>\n",
       "      <th>标注类别名称</th>\n",
       "      <th>top-1-预测ID</th>\n",
       "      <th>top-1-预测名称</th>\n",
       "      <th>top-2-预测ID</th>\n",
       "      <th>top-2-预测名称</th>\n",
       "      <th>top-3-预测ID</th>\n",
       "      <th>top-3-预测名称</th>\n",
       "      <th>top-n预测正确</th>\n",
       "      <th>covering-预测置信度</th>\n",
       "      <th>device-预测置信度</th>\n",
       "      <th>domestic_animal-预测置信度</th>\n",
       "      <th>mater-预测置信度</th>\n",
       "      <th>person-预测置信度</th>\n",
       "      <th>plant-预测置信度</th>\n",
       "      <th>structure-预测置信度</th>\n",
       "      <th>vertebrate-预测置信度</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/SOD-SemanticDataset/test/COME15K-Easy/COM...</td>\n",
       "      <td>0</td>\n",
       "      <td>covering</td>\n",
       "      <td>3</td>\n",
       "      <td>mater</td>\n",
       "      <td>1</td>\n",
       "      <td>device</td>\n",
       "      <td>6</td>\n",
       "      <td>structure</td>\n",
       "      <td>False</td>\n",
       "      <td>0.053483</td>\n",
       "      <td>0.221736</td>\n",
       "      <td>0.001853</td>\n",
       "      <td>0.478643</td>\n",
       "      <td>0.015743</td>\n",
       "      <td>0.007416</td>\n",
       "      <td>0.206461</td>\n",
       "      <td>0.014667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data/SOD-SemanticDataset/test/COME15K-Easy/COM...</td>\n",
       "      <td>0</td>\n",
       "      <td>covering</td>\n",
       "      <td>2</td>\n",
       "      <td>domestic_animal</td>\n",
       "      <td>4</td>\n",
       "      <td>person</td>\n",
       "      <td>7</td>\n",
       "      <td>vertebrate</td>\n",
       "      <td>False</td>\n",
       "      <td>0.065810</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>0.730829</td>\n",
       "      <td>0.007129</td>\n",
       "      <td>0.097066</td>\n",
       "      <td>0.001619</td>\n",
       "      <td>0.002674</td>\n",
       "      <td>0.093673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data/SOD-SemanticDataset/test/COME15K-Easy/COM...</td>\n",
       "      <td>0</td>\n",
       "      <td>covering</td>\n",
       "      <td>4</td>\n",
       "      <td>person</td>\n",
       "      <td>5</td>\n",
       "      <td>plant</td>\n",
       "      <td>6</td>\n",
       "      <td>structure</td>\n",
       "      <td>False</td>\n",
       "      <td>0.099537</td>\n",
       "      <td>0.015642</td>\n",
       "      <td>0.002969</td>\n",
       "      <td>0.060892</td>\n",
       "      <td>0.297557</td>\n",
       "      <td>0.256265</td>\n",
       "      <td>0.151516</td>\n",
       "      <td>0.115622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data/SOD-SemanticDataset/test/COME15K-Easy/COM...</td>\n",
       "      <td>0</td>\n",
       "      <td>covering</td>\n",
       "      <td>0</td>\n",
       "      <td>covering</td>\n",
       "      <td>4</td>\n",
       "      <td>person</td>\n",
       "      <td>3</td>\n",
       "      <td>mater</td>\n",
       "      <td>True</td>\n",
       "      <td>0.514543</td>\n",
       "      <td>0.002269</td>\n",
       "      <td>0.005743</td>\n",
       "      <td>0.012137</td>\n",
       "      <td>0.446524</td>\n",
       "      <td>0.005227</td>\n",
       "      <td>0.008116</td>\n",
       "      <td>0.005442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data/SOD-SemanticDataset/test/COME15K-Easy/COM...</td>\n",
       "      <td>0</td>\n",
       "      <td>covering</td>\n",
       "      <td>4</td>\n",
       "      <td>person</td>\n",
       "      <td>0</td>\n",
       "      <td>covering</td>\n",
       "      <td>7</td>\n",
       "      <td>vertebrate</td>\n",
       "      <td>True</td>\n",
       "      <td>0.300385</td>\n",
       "      <td>0.001374</td>\n",
       "      <td>0.025110</td>\n",
       "      <td>0.004683</td>\n",
       "      <td>0.617911</td>\n",
       "      <td>0.006019</td>\n",
       "      <td>0.003014</td>\n",
       "      <td>0.041503</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                图像路径  标注类别ID    标注类别名称   \n",
       "0  data/SOD-SemanticDataset/test/COME15K-Easy/COM...       0  covering  \\\n",
       "1  data/SOD-SemanticDataset/test/COME15K-Easy/COM...       0  covering   \n",
       "2  data/SOD-SemanticDataset/test/COME15K-Easy/COM...       0  covering   \n",
       "3  data/SOD-SemanticDataset/test/COME15K-Easy/COM...       0  covering   \n",
       "4  data/SOD-SemanticDataset/test/COME15K-Easy/COM...       0  covering   \n",
       "\n",
       "   top-1-预测ID       top-1-预测名称  top-2-预测ID top-2-预测名称  top-3-预测ID  top-3-预测名称   \n",
       "0           3            mater           1     device           6   structure  \\\n",
       "1           2  domestic_animal           4     person           7  vertebrate   \n",
       "2           4           person           5      plant           6   structure   \n",
       "3           0         covering           4     person           3       mater   \n",
       "4           4           person           0   covering           7  vertebrate   \n",
       "\n",
       "   top-n预测正确  covering-预测置信度  device-预测置信度  domestic_animal-预测置信度   \n",
       "0      False        0.053483      0.221736               0.001853  \\\n",
       "1      False        0.065810      0.001200               0.730829   \n",
       "2      False        0.099537      0.015642               0.002969   \n",
       "3       True        0.514543      0.002269               0.005743   \n",
       "4       True        0.300385      0.001374               0.025110   \n",
       "\n",
       "   mater-预测置信度  person-预测置信度  plant-预测置信度  structure-预测置信度  vertebrate-预测置信度  \n",
       "0     0.478643      0.015743     0.007416         0.206461          0.014667  \n",
       "1     0.007129      0.097066     0.001619         0.002674          0.093673  \n",
       "2     0.060892      0.297557     0.256265         0.151516          0.115622  \n",
       "3     0.012137      0.446524     0.005227         0.008116          0.005442  \n",
       "4     0.004683      0.617911     0.006019         0.003014          0.041503  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e7d010-df35-4fb9-8dcb-1af2d5399681",
   "metadata": {},
   "source": [
    "## 计算测试集每张图像的语义特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0d630667-6b6b-4fdd-8c4d-28286499330b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 4600/4600 [00:59<00:00, 77.79it/s]\n"
     ]
    }
   ],
   "source": [
    "encoding_array = []\n",
    "img_path_list = []\n",
    "\n",
    "for img_path in tqdm(df['图像路径']):\n",
    "    img_path_list.append(img_path)\n",
    "    img_pil = Image.open(img_path).convert('RGB')\n",
    "    input_img = test_transform(img_pil).unsqueeze(0).to(device) # 预处理\n",
    "    feature = model_trunc(input_img)['semantic_feature'].squeeze().detach().cpu().numpy() # 执行前向预测，得到 avgpool 层输出的语义特征\n",
    "    encoding_array.append(feature)\n",
    "encoding_array = np.array(encoding_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fec12f5b-35d0-4367-8ac1-7d7321eecee9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4600, 1280)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding_array.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c434aad3-9689-4e77-bef7-1daa4400e590",
   "metadata": {},
   "source": [
    "## 保存为本地的.npy文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "896a318d-430c-4b59-9c94-0b08ba0106dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 保存为本地的 npy 文件\n",
    "np.save(model_path + dataset_name + '-测试集语义特征.npy', encoding_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4417cdc4-0bad-428c-896f-1d35d31401a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:SemanticTest]",
   "language": "python",
   "name": "conda-env-SemanticTest-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
